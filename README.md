*This project has been created as part of the 42 curriculum by marberge, stmaire.*             

---

<div align="center">
<br>
  <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTQPzuYKu7n0cWUYa5Kbg0_LrlEQAIURWeo9A&s" alt="42 Logo" width="400" />

  <br>
</div>

# push_swap

![Language](https://img.shields.io/badge/Language-C-blue)
![Bonus](https://img.shields.io/badge/Bonus-No-red)
![Grade](https://img.shields.io/badge/Grade-100%2F100-brightgreen)
![Tag](https://img.shields.io/badge/Algorithm-grey)
![Tag](https://img.shields.io/badge/Complexity-grey)
![Tag](https://img.shields.io/badge/Optimization-grey)


**Push_swap** est un projet d'algorithmique avanc√© qui consiste √† trier des donn√©es sur une pile (stack), avec un jeu d'instructions limit√© et en un nombre de coups strictement optimis√©.

Le d√©fi principal n'est pas seulement de trier, mais de le faire avec une **efficacit√© math√©matique**. Le programme ne se contente pas d'appliquer une m√©thode unique : il est con√ßu pour √™tre **intelligent et adaptatif**, analysant les donn√©es avant d'agir.

---

## 1. Description

<details>
<summary><strong>üéÆ Les R√®gles du Jeu</strong></summary>

Le projet fonctionne avec deux piles : **Stack A** et **Stack B**.

1.  **√âtat Initial :**
    * **Stack A** : Contient une liste al√©atoire d'entiers (positifs ou n√©gatifs), sans doublons.
    * **Stack B** : Est vide.
2.  **Objectif :**
    * Trier les nombres de la **Stack A** par ordre croissant (le plus petit au sommet).
    * La **Stack B** doit √™tre vide √† la fin de l'ex√©cution.
3.	**Les op√©rations disponibles :**

	* **üîÑ Swap (√âchange)**

* `sa` **(swap a)** : √âchange les deux premiers √©l√©ments au sommet de la pile `a`. (Ne fait rien s'il n'y a qu'un ou aucun √©l√©ment).
* `sb` **(swap b)** : √âchange les deux premiers √©l√©ments au sommet de la pile `b`. (Ne fait rien s'il n'y a qu'un ou aucun √©l√©ment).
* `ss` : Effectue `sa` et `sb` en m√™me temps.

	* **üì§ Push (Pousser)**

* `pa` **(push a)** : Prend le premier √©l√©ment au sommet de `b` et le place sur `a`. (Ne fait rien si `b` est vide).
* `pb` **(push b)** : Prend le premier √©l√©ment au sommet de `a` et le place sur `b`. (Ne fait rien si `a` est vide).

	* **‚¨ÜÔ∏è Rotate (Rotation)**

* `ra` **(rotate a)** : D√©cale d'une position vers le haut tous les √©l√©ments de la pile `a`. (Le premier √©l√©ment devient le dernier).
* `rb` **(rotate b)** : D√©cale d'une position vers le haut tous les √©l√©ments de la pile `b`. (Le premier √©l√©ment devient le dernier).
* `rr` : Effectue `ra` et `rb` en m√™me temps.

	* **‚¨áÔ∏è Reverse Rotate (Rotation Inverse)**

* `rra` **(reverse rotate a)** : D√©cale d'une position vers le bas tous les √©l√©ments de la pile `a`. (Le dernier √©l√©ment devient le premier).
* `rrb` **(reverse rotate b)** : D√©cale d'une position vers le bas tous les √©l√©ments de la pile `b`. (Le dernier √©l√©ment devient le premier).
* `rrr` : Effectue `rra` et `rrb` en m√™me temps.

4. **üöÄ Le D√©fi de la Complexit√©**

Pour atteindre le grade "Excellent", ce programme impl√©mente une **strat√©gie adaptative**. Avant de trier, il calcule le **taux de d√©sordre** de la liste pour s√©lectionner l'algorithme le plus performant en fonction du d√©sordre et de la taille de la liste √† trier.

</details>

<details>
<summary><strong>‚ö° Modes de Fonctionnement</strong></summary>



Afin de faciliter le contr√¥le des performances, le programme int√®gre plusieurs modes d'ex√©cution activables via des drapeaux (flags):

* **Mode Automatique (Par d√©faut)** : Le programme est autonome. Il scanne la pile et choisit la meilleure strat√©gie pour minimiser les coups.
* **Modes Forc√©s (`--simple`, `--medium`, `--complex`)** : Ces options permettent de d√©sactiver l'intelligence artificielle du programme pour forcer l'utilisation d'un algorithme sp√©cifique, quelle que soit la taille de la liste. C'est id√©al pour v√©rifier la robustesse de chaque m√©thode individuellement.
* **Mode Benchmark (`--bench`)** : Transforme le programme en outil d'analyse scientifique. En plus de trier, il calcule et affiche des statistiques pr√©cises sur la **sortie d'erreur** (taux de d√©sordre, strat√©gie utilis√©e, compteurs d'op√©rations d√©taill√©s), permettant une validation rigoureuse sans perturber le checker.

</details> 

## 2. Instructions

<details>
<summary><strong>üîß Compilation</strong></summary>




Le projet est √©crit en C et utilise un `Makefile` pour la compilation. Assurez-vous d'avoir `gcc` et `make` install√©s sur votre machine.
Cette commande g√©n√®re l'ex√©cutable `push_swap`.

```bash
    make
```

---

</details>

<details>
<summary><strong>üöÄ Ex√©cution</strong></summary>


Le programme prend en argument une liste d'entiers √† trier.

**Syntaxe de base :**
```bash
./push_swap [NOMBRES...]
```
**Exemple simple :**
```bash
./push_swap 42 1337 -21 0 5
```
Utilisation avec une variable (Recommand√©) : Pour tester facilement la m√™me liste avec le programme et le checker.
```bash
ARG="4 67 3 87 23"; ./push_swap $ARG
```

</details>

<details>
<summary><strong>üö© Options & Drapeaux</strong></summary>


Vous pouvez ajouter un drapeau **avant** la liste de nombres pour modifier le comportement du programme.

#### 1. Forcer une strat√©gie sp√©cifique
Par d√©faut, le programme est adaptatif. Pour tester manuellement un algorithme pr√©cis :

##### Force l'algorithme quadratique (Simple)
```bash
./push_swap --simple 4 2 5 1
```
##### Force l'algorithme par chunks (Moyen)
```bash
push_swap --medium $ARG
```
##### Force l'algorithme optimis√© (Complexe)
```bash
./push_swap --complex $ARG
```
#### 2. Activer le mode Benchmark
Pour obtenir les statistiques de tri (d√©sordre, complexit√©, compteurs) sur la sortie d'erreur (`stderr`) :

```bash
./push_swap --bench $ARG
```

</details>

<details>
<summary><strong>‚úÖ V√©rification (Checker)</strong></summary>


Le programme est con√ßu pour √™tre utilis√© en "pipe" avec le binaire de v√©rification (`checker_linux` ou votre propre bonus checker).

**Commande standard :**
```bash
ARG="4 67 3 87 23"; ./push_swap $ARG | ./checker_linux $ARG
```
*La sortie doit afficher `OK` si le tri est valide.*

**V√©rification avec le Benchmark actif :**
Comme le benchmark √©crit sur la sortie d'erreur (`stderr`), il ne perturbe pas le checker qui lit uniquement la sortie standard (`stdout`) :

```bash
./push_swap --bench $ARG | ./checker_linux $ARG
```

</details> 

<details>
<summary><strong>üßπ Nettoyage</strong></summary>



* **`make clean`** : Supprime les fichiers objets (`.o`).
* **`make fclean`** : Supprime les fichiers objets et l'ex√©cutable `push_swap`.
* **`make re`** : Recompile tout depuis z√©ro.
</details>

## 3. Ressources et r√©f√©rences 

<details>
<summary><strong>üß† Algorithmes & Strat√©gies</strong></summary>

Voici une s√©lection de ressources techniques pour comprendre les algorithmes impl√©ment√©s et les outils utilis√©s pour valider le projet.

* **[Push_swap ‚Äî A journey to find the optimal sorting algorithm](https://medium.com/nerd-for-tech/push-swap-v2-comprehensive-guide-434f86d60661)** : Explication du **Radix Sort** (tri par base), l'alternative math√©matique binaire pour garantir une complexit√© $O(n \log n)$.
* **[Big O Cheat Sheet](https://www.bigocheatsheet.com/)** : Le tableau de r√©f√©rence pour visualiser graphiquement les diff√©rences de performance entre $O(n^2)$ (Simple), $O(n\sqrt{n})$ (Moyen) et $O(n \log n)$ (Complexe).

* **[Wikipedia : Tri par insertion](https://fr.wikipedia.org/wiki/Tri_par_insertion)**
* **[Wikipedia : Tri par selection](https://fr.wikipedia.org/wiki/Tri_par_selection)**
* **[Wikipedia : Tri √† bulles](https://fr.wikipedia.org/wiki/Tri_%C3%A0_bulles)**
* **[Wikipedia : Bucket sort](https://en.wikipedia.org/wiki/Bucket_sort)**
* **[Wikipedia : Radix sort](https://fr.wikipedia.org/wiki/Tri_par_base)**
* **[Wikipedia : Merge sort](https://fr.wikipedia.org/wiki/Tri_fusion)**
* **[Wikipedia : Quick sort](https://fr.wikipedia.org/wiki/Tri_rapide)**
* **[Wikipedia : Heap sort](https://fr.wikipedia.org/wiki/Tri_par_tas)**

</details>

<details>
<summary><strong>üõ†Ô∏è Outils de Test & Visualisation</strong></summary>


* **[push_swap_visualizer (o-reo)](https://github.com/o-reo/push_swap_visualizer)** : Un outil graphique indispensable pour **voir** les piles bouger en temps r√©el. Il permet de comprendre visuellement la logique de tri et de d√©bugger les boucles infinies.
* **[push_swap_tester (SimonCROS)](https://github.com/SimonCROS/push_swap_tester)** : Un script de benchmark complet pour lancer des milliers de tests al√©atoires, v√©rifier la gestion des erreurs et calculer la moyenne de coups. Essentiel pour calibrer le mode adaptatif.

</details>

<details>
<summary><strong>ü§ñ Utilisation de l'IA</strong></summary>


Dans le cadre de ce projet, l'intelligence artificielle a √©t√© utilis√©e comme un outil d'assistance compl√©mentaire aux recherches traditionnelles. Elle est intervenue sur trois axes principaux :
* **Support Th√©orique :** Aide √† la vulgarisation et √† la compr√©hension de concepts algorithmiques avanc√©s (calcul de complexit√© temporelle/spatiale, notation Big O) et math√©matiques (calcul du taux de d√©sordre d'une liste).
* **G√©n√©ration de Tests :** Cr√©ation de jeux de donn√©es sp√©cifiques, notamment des s√©ries de nombres respectant des pourcentages de d√©sordre pr√©cis, pour √©prouver la robustesse des algorithmes de tri.
* **D√©bogage :** Assistance √† l'analyse de code pour l'identification d'erreurs logiques et la r√©solution de probl√®mes de gestion de m√©moire (segmentation faults).
</details>

## 4. Strat√©gies Algorithmiques & Complexit√©

<!-- Pour r√©soudre efficacement le probl√®me de tri quelle que soit la taille de l'entr√©e, ce projet impl√©mente trois approches algorithmiques distinctes, allant de la m√©thode na√Øve √† la plus optimis√©e, conform√©ment aux exigences du sujet. -->

<details>
<summary><strong>üü¢ L'Algorithme Simple O(n¬≤)</strong></summary>

* **Cible :** Petites piles (3 √† ~20 valeurs).

* **Strategies possibles (quelques exemples) :**

-- **Bubble sort** : On parcourt la pile. Si le nombre du haut est plus grand que le suivant, on les √©change (sa). Sinon, on passe au suivant (ra). Apr√®s un premier parcours complet du tableau, le plus grand √©l√©ment est forc√©ment en fin de tableau, √† sa position d√©finitive. On recommence √† parcourir le tableau tant que tout n'est pas tri√©. Cet algorithme consomme √©norm√©ment de mouvements (sa, ra en boucle). 

-- **Tri par insertion (Insertion Sort) :** On prend le nombre en haut de `a` (pb), et on l'ins√®re √† la bonne place dans la pile `b` (qui est toujours tri√©e). √Ä la fin, on remet tout dans `a`. Solution complexe √† coder car, vu qu'elle ins√®re au bon endroit dans la pile, cela demande de calculer les co√ªts de rotation.

-- **Tri par S√©lection :** L'algorithme parcourt la totalit√© de la pile `a` pour trouver le plus petit nombre (minimum), le pousse vers la pile `b`, et r√©p√®te le processus jusqu'√† ce que `a` soit vide. Tr√®s facile √† coder. Co√ªt √©lev√© (~ n √ó n op√©rations), mais suffisamment efficace pour de tr√®s petites listes o√π la surcharge est minime.

-- **L'Extraction Min/Max (Extraction Method) :**
C'est une version plus "flexible" du tri par s√©lection, qui peut √™tre utilis√©e pour optimiser les coups. Il s'agit de vider la pile `a`A le plus vite possible en enlevant les "extr√™mes". La m√©thode : Regarder la pile `a`. Se demander : "Qui est le plus pr√®s du haut ? Le Minimum ou le Maximum ?" Si le Min est plus pr√®s : on le monte et pb (et on le laisse en haut de `b`). Si le Max est plus pr√®s : on le monte et pb (et on le met en bas de 'b' avec rb). La pile `b` est donc tri√©e au fur et √† mesure, mais on a √©conomis√© des rotations en choisissant le chemin le plus court (vers le Min ou vers le Max). NB : au del√† de 3 nombres, cela ne fonctionne plus sans adaptations car `b` n'est plus tri√©...

</details>

<details>
<summary><strong>üü° L'Algorithme Moyen O(n‚àön)</strong></summary>

* **Cible :** Piles moyennes (ex : 100 valeurs).

* **Strat√©gie :** **Chunk-based sorting (Tri par paquets)** 
* **Fonctionnement :**
	1.	On commence par indexer les valeurs en rempla√ßant les valeurs r√©elles par leur rang.
    1.  La pile est virtuellement divis√©e en plages de valeurs appel√©es "chunks". Le nombre de chunks est d√©termin√© par la racine carr√©e du nombre total d'√©l√©ments (‚àön).
    2.  Au lieu de chercher un nombre pr√©cis (comme le minimum exact), l'algorithme cherche **n'importe quel** nombre appartenant au chunk actuel.
    3.  Une fois pouss√©s sur la pile `b`, les √©l√©ments sont grossi√®rement tri√©s par groupes. Ils sont ensuite repouss√©s vers `a` avec un tri pr√©cis.
* **Pourquoi O(n‚àön) ?** Chercher "n'importe quel √©l√©ment d'un chunk" est statistiquement bien plus rapide que de chercher un √©l√©ment sp√©cifique. On effectue `n` pouss√©es, mais avec un co√ªt de recherche r√©duit √† `‚àön` en moyenne.

* **Variantes de cette strat√©gie (quelques exemples):**

-- **Block-based partitioning (Partitionnement par blocs)**
Variante du tri par paquets, cette approche se concentre sur la structure de la pile. Au lieu de d√©finir des plages de valeurs strictes, on divise la pile initiale en segments ou "blocs" logiques. L'objectif est de d√©placer des blocs entiers d'√©l√©ments vers la pile B en optimisant les mouvements. Une fois dans B, chaque bloc est consid√©r√© comme une sous-section ind√©pendante, ce qui r√©duit la complexit√© de recherche du prochain √©l√©ment √† trier (on ne cherche que dans le bloc actif au sommet).

-- **Bucket sort adaptations (Adaptation du tri par seaux)**

Le tri par seaux classique distribue les √©l√©ments dans plusieurs contenants distincts. Dans Push_swap, n'ayant qu'une seule pile B, on adapte ce principe en empilant les "seaux" les uns sur les autres. On d√©finit n‚Äã intervalles de valeurs (les seaux). On parcourt la pile A et on envoie les √©l√©ments dans la pile B en les regroupant par intervalle. L'astuce r√©side dans la gestion de l'empilement dans B pour garder les seaux accessibles ou partiellement tri√©s via des rotations judicieuses (rb).

-- **Range-based sorting strategies (Strat√©gies par intervalles dynamiques)**

C'est souvent l'√©volution la plus performante du tri par paquets. Au lieu d'avoir des paquets fixes (ex: 1 √† 20), on utilise une "fen√™tre glissante" ou un intervalle dynamique (= le range). Si le nombre au sommet de A est compris dans l'intervalle [0, compteur + range] (compteur = nombre d'√©lements d√©j√† pr√©-tri√©s), on le pousse vers B. √Ä chaque push, l'intervalle grandit ou se d√©cale. Cette m√©thode lisse la distribution des nombres dans la pile B (souvent en forme de courbe de Gauss) et minimise les rotations n√©cessaires pour r√©cup√©rer les √©l√©ments extr√™mes lors de la phase finale. A la fin, les plus grands nombres (ceux qui sont rentr√©s en dernier) sont globalement vers le haut de la pile, et les plus petits (rentr√©s au d√©but) sont vers le bas ou le milieu. Enfin, il reste √† reconstruire la pile A √† l'envers, en cherchant le maximum dans `b` qui a √©t√© pr√©-tri√©.

</details>

<details>
<summary><strong>üî¥ L'Algorithme Complexe O(n log n)</strong></summary>


* **Cible :** Grandes piles (500+ valeurs).
* **Pourquoi O(n log n) ?**
    * En informatique, **log n** (logarithme en base 2) est la r√©ponse √† la question : **"Combien de fois puis-je couper ma liste en deux avant qu'il ne reste plus qu'un seul √©l√©ment ?"**
    * Pour 500 nombres, la r√©ponse est seulement 9 (log‚ÇÇ 500 ‚âà 9).
    * Au lieu de faire 500 tours de boucle (comme le tri simple), cet algorithme ne n√©cessite qu'environ 9 niveaux de division pour isoler et trier chaque nombre. C'est ce qui le rend exponentiellement plus rapide.

* **Strat√©gies possibles (quelques exemples) :**

-- **Radix sort adaptation (LSD or MSD) :** 
		
Contrairement aux tris classiques qui comparent les valeurs entre elles (a > b), le Radix trie les nombres en traitant leurs chiffres individuellement. 
Pour ce projet, il est possible d'utiliser une version binaire (Base 2) de l'algorithme, particuli√®rement adapt√©e aux op√©rations bit-√†-bit :
Deux approches sont possibles :

LSD = Least Significant Digit (Chiffre le Moins Significatif).
    On commence par la droite (les unit√©s, ou ici le bit 0).
    On remonte vers la gauche. 

MSD = Most Significant Digit (Chiffre le Plus Significatif).
    On commence par la gauche (les milliers, ou ici le bit le plus fort).
    On descend vers la droite.



<details>
<summary><strong> ‚û°Ô∏è Tableau comparatif LSD/MSD</strong></summary>

| Crit√®re | LSD (Least Significant Digit) | MSD (Most Significant Digit) |
| :--- | :--- | :--- |
| **Logique** | De Droite √† Gauche (Bit 0 $\rightarrow$ Bit Max) | De Gauche √† Droite (Bit Max $\rightarrow$ Bit 0) |
| **Structure** | **It√©ratif** (Une simple boucle `for`) | **R√©cursif** (N√©cessite des appels de fonctions imbriqu√©s) |
| **Gestion des Piles** | On traite **toute** la pile A √† chaque tour (A $\leftrightarrow$ B). | On doit g√©rer des **sous-portions** de piles isol√©es. |
| **Complexit√© Code** | ‚úÖ **Tr√®s facile** (Id√©al pour Push_swap). | ‚ö†Ô∏è **Difficile** (Gestion d'index et de r√©cursivit√© complexe). |
| **Efficacit√©** | **Constante** (Le nombre de coups est pr√©visible). | **Variable** (Potentiellement plus rapide, mais dur √† optimiser).

</details>

---

<br>

 
 Les valeurs r√©elles sont d'abord simplifi√©es par leur rang (de 0 √† N-1). Cela permet de travailler avec des entiers positifs et contigus, r√©duisant la complexit√©. L'algorithme parcourt ensuite les nombres bit par bit, du moins significatif (droite) au plus significatif (gauche). Si le bit actuel est 0 : Le nombre est pouss√© vers la pile B. Si le bit actuel est 1 : Le nombre reste dans la pile A (rotation). Apr√®s avoir trait√© un bit pour toute la pile, le contenu de B est revers√© dans A, et le cycle recommence pour le bit suivant.


-- **Merge sort adaptation using two stacks :** 

Le Merge Sort est l'exemple classique de l'approche algorithmique "Diviser pour r√©gner" (Divide and Conquer). C'est un tri par comparaison tr√®s efficace, particuli√®rement adapt√© aux structures de donn√©es s√©quentielles comme les listes cha√Æn√©es.
- Diviser : On coupe la pile principale en deux sous-piles √©gales (r√©cursivement) jusqu'√† obtenir des piles d'un seul √©l√©ment.
- R√©gner : Une pile d'un seul √©l√©ment est consid√©r√©e comme tri√©e.
- Combiner (Fusion) : C'est l'√©tape cl√©. On fusionne deux sous-piles tri√©es pour en former une plus grande, en comparant √† chaque fois les √©l√©ments au sommet pour ins√©rer le plus petit (ou le plus grand) en premier.
- Performance : Il offre une complexit√© garantie de O(n log n) dans tous les cas (pire, moyen et meilleur), ce qui le rend tr√®s fiable.

Note pour Push_swap : Bien que tr√®s performant th√©oriquement, son impl√©mentation avec seulement deux piles et des rotations demande une gestion rigoureuse pour simuler la division et la fusion sans acc√®s al√©atoire √† la m√©moire.

-- **Quick sort adaptation with stack partitioning :** 

La m√©thode consiste √† placer un √©l√©ment du tableau (appel√© pivot) √† sa place d√©finitive, en permutant tous les √©l√©ments de telle sorte que tous ceux qui sont inf√©rieurs au pivot soient √† sa gauche et que tous ceux qui sont sup√©rieurs au pivot soient √† sa droite.

Cette op√©ration s'appelle le partitionnement. Pour chacun des sous-tableaux, on d√©finit un nouveau pivot et on r√©p√®te l'op√©ration de partitionnement. Ce processus est r√©p√©t√© r√©cursivement, jusqu'√† ce que l'ensemble des √©l√©ments soit tri√©. 

-- **Heap sort adaptation :** 

Le tri par tas (Heap Sort) est un algorithme de comparaison efficace et en place qui structure les donn√©es sous forme d'un arbre binaire (appel√© "tas" ou heap), g√©n√©ralement un Tas-Max o√π chaque n≈ìud est sup√©rieur √† ses enfants. Le fonctionnement repose sur deux √©tapes cl√©s : d'abord, on transforme le tableau entier en un tas pour que l'√©l√©ment le plus grand se retrouve obligatoirement √† la racine (au d√©but du tableau) ; ensuite, on √©change it√©rativement cette racine avec le dernier √©l√©ment de la zone non tri√©e, on r√©duit la taille du tas consid√©r√©, et on r√©organise ("entasse") la structure pour faire remonter le nouveau maximum au sommet. Ce processus r√©p√©t√© d√©place progressivement les plus grands √©l√©ments vers la fin du tableau, garantissant un tri avec une complexit√© temporelle optimale de O(nlogn) dans tous les cas, sans n√©cessiter de m√©moire suppl√©mentaire importante.

-- **Binary indexed tree approaches :** 

Le BST sort (Binary Search Tree ou arbre de recherche binaire) recourt aussi aux arbres binaires mais la logique de rangement est diff√©rente : contrairement au heap sort o√π l'√©l√©ment le plus grand est en haut, ici tout ce qui est plus petit doit aller √† gauche, tout ce qui est plus grand doit aller √† droite.
exemple :

<details><summary>‚û°Ô∏è Exemple : Tri par Arbre Binaire de Recherche (BST) üå≥</summary>

**Tableau initial :** `[4, 10, 3, 5, 1]`

#### √âtape 1 : Construction de l'arbre (Insertion)
| Tour | Nombre | Comparaisons (Le Chemin) | Action finale |
| :---: | :---: | :--- | :--- |
| 1 | **4** | *(L'arbre est vide)* | Devient la **Racine**. |
| 2 | **10** | 10 > 4 ‚ûî Droite | Devient l'enfant **Droit** de 4. |
| 3 | **3** | 3 < 4 ‚ûî Gauche | Devient l'enfant **Gauche** de 4. |
| 4 | **5** | 5 > 4 (Droite) ‚ûî 5 < 10 (Gauche) | Devient l'enfant **Gauche** de 10. |
| 5 | **1** | 1 < 4 (Gauche) ‚ûî 1 < 3 (Gauche) | Devient l'enfant **Gauche** de 3. |

#### R√©sultat Visuel
L'arbre final ressemble √† ceci :

```text
       4
     /   \
    3     10
   /     /
  1     5
```

---

### Ce que √ßa donne une fois rendu :

### üå≥ Exemple : Tri par Arbre Binaire de Recherche (BST)

**Tableau initial :** `[4, 10, 3, 5, 1]`

#### √âtape 1 : Construction de l'arbre (Insertion)
| Tour | Nombre | Comparaisons (Le Chemin) | Action finale |
| :---: | :---: | :--- | :--- |
| 1 | **4** | *(L'arbre est vide)* | Devient la **Racine**. |
| 2 | **10** | 10 > 4 ‚ûî Droite | Devient l'enfant **Droit** de 4. |
| 3 | **3** | 3 < 4 ‚ûî Gauche | Devient l'enfant **Gauche** de 4. |
| 4 | **5** | 5 > 4 (Droite) ‚ûî 5 < 10 (Gauche) | Devient l'enfant **Gauche** de 10. |
| 5 | **1** | 1 < 4 (Gauche) ‚ûî 1 < 3 (Gauche) | Devient l'enfant **Gauche** de 3. |

#### R√©sultat Visuel
L'arbre final ressemble √† ceci :

```text
       4
     /   \
    3     10
   /     /
  1     5
```
#### √âtape 2 : Lecture (Parcours Infixe / In-Order)
On parcourt l'arbre en suivant la r√®gle stricte : **Gauche ‚ûî Racine ‚ûî Droite**.

1.  On part de **4**, on va tout √† gauche ‚ûî **3**, encore √† gauche ‚ûî **1**. (Rien √† gauche de 1).
    * üìù On note : `1`
2.  On remonte au parent de 1.
    * üìù On note : `3`
3.  On regarde √† droite de 3 (Rien). On remonte √† la racine.
    * üìù On note : `4`
4.  On va √† droite de 4 (vers le **10**). On regarde d'abord sa gauche (le **5**).
    * üìù On note : `5`
5.  On remonte au **10**.
    * üìù On note : `10`

‚úÖ **R√©sultat tri√© :** `1, 3, 4, 5, 10`

</details>

---

<br>

</details>

<details>
<summary><strong>üü§ Compl√©ment : Tri stable et tri instable</strong></summary>

La notion de stabilit√© est fondamentale en algorithmique. Elle d√©signe la capacit√© d'un tri √† pr√©server l'ordre relatif des √©l√©ments ayant la m√™me valeur (doublons).

* **Tri Stable (Stable Sort)** : Si deux √©l√©ments sont √©gaux, celui qui apparaissait en premier dans la liste originale restera en premier dans la liste tri√©e. C'est crucial lorsqu'on effectue des tris multicrit√®res (ex: trier par nom, puis par √¢ge sans perdre le tri alphab√©tique).

Exemples : Insertion Sort, Bubble Sort, Merge Sort.

* **Tri Instable (Unstable Sort)** : L'ordre relatif des √©l√©ments √©gaux n'est pas garanti et peut √™tre modifi√© al√©atoirement durant le processus. Ces algorithmes sont souvent plus rapides ou √©conomes en m√©moire, mais "perdent" l'information de l'ordre initial pour les doublons.

Exemples : Quick Sort, Selection Sort, Heap Sort.

</details>

## 5. D√©marche et √©tapes de r√©alisation du projet

<details>
<summary><strong>üÜó Parsing</strong></summary>

* **fonction from_args_to_big_str :** r√©cup√©rer les arguments entr√©s par l'utilisateur (sous la forme : "1 3 -12" ou  1 3 -12 ou encore un mixte des deux -par exemple : "1 3 " -12) et les placer dans une "big_str"
* **fonction put_args_in_array :** split de cette "big_str" dans un tableau de tableau (chaque ligne contient une string entr√©e par l'utilisateur, qui sera √† transformer en entier)
* **fonction build_stack :**  v√©rifie la validit√© des arguments donn√©s 
	-	on v√©rifie d 'abord qu'il ne s'agit bien que de nombres
	-	on les transforme en entiers en utilisant atol plut√¥t que atoi (en cas d'overflow). Si atol renvoie bien un nombre, on v√©rifie l'oveflow.
	-	on v√©rifie l'absence de doublons.
	- si tout va bien, on construit la liste cha√Æn√©e gr√¢ce √† la fonction suivante.
* **NB :** Les fonctions relatives √† la liste cha√Æn√©e sont des variantes des fonctions de la libft, adapt√©es √† la structure t_stack 
* **append_node :** fonction qui ajoute un nouveau noeud √† la fin de la liste cha√Æn√©e. Chaque nouveau noeud stocke la valeur d'un entier r√©cup√©r√©. Plus on avance dans les noeuds, plus on descend dans la pile.
* ex 1 2 3 donnera : 	1
						2
						3
* **NB :** Pour l'instant la structure est incompl√®te et ne contient pas les infos n√©cessaires au mode -benchmark
	typedef struct s_stack_node

```{
	/* data to complete */
	int					number;
	struct s_stack_node	*prev; // liste doublement cha√Æn√©e pour faciliter ensuite les mouvements
	struct s_stack_node	*next;
}						t_stack;
```
* **index*** : Il s'agit d'associer un index √† chaque valeur (!!!une fois la liste cha√Æn√©e compl√©t√©e) pour travailler ensuite sur les index, ce qui r√®gle le probl√®me des nombres n√©gatifs et simplifie beaucoup le traitement. On a a priori besoin des index pour les algo moyens et complexes. Cet index doit √™tre ajout√© √† la structure qui devient alors :

```{
	/* data to complete */
	int					number;
	int					index //le rang de l'entier dans la liste
	struct s_stack_node	*prev;
	struct s_stack_node	*next;
}						t_stack;
```
* **Pour compl√©ter ce champ index :** *
* **fonction index_stack**(dans le fichier sort_numbers) : On commence par mesurer la taille de la liste cha√Æn√©e pour allouer la m√©moire d'un tableau, dans lequel on copie les entiers. On travaille avec une copie du noeud pour √©viter de perdre l'adresse de la liste. Dans ce tableau, on trie les entiers avec un bubble sort(* **fonction sort_numbers** *)(NB on se moque de la performance de ce pr√©-tri, c'est la performance des algos qui sera ensuite √©valu√©e). 
Enfin, la fonction * **find_index** * cherche la correspondance entre l¬¥entier stock√© dans la liste cha√Æn√©e et les valeurs du tableau tri√© (ex : tableau tri√© [2, 14, 22]) > je cherche dans quel noeud se trouve stock√©e la valeur "2" et j'associe √† ce noeud l'index 0... etc...

</details>

<details>
<summary><strong>üìù Choix et impl√©mentation des algorithmes</strong></summary>

### A. algorithme simple :
* **Strat√©gie choisie : tri par s√©lection**.

	Nous avons choisi d'impl√©menter un tri par s√©lection pour le ratio simplicit√©/efficacit√© de cet algorithme pour le tri des petites listes. Nous avons cherch√© √† optimiser le tri en traitant √† part les trois derniers nombres qui restent de la pile a (ou le tri se fait en un ou deux mouvements seulement). Un seconde optimisation consiste √† faire tourner la pile dans un sens ou dans l'autre pour faire remonter l'index voulu en haut de la pile en fonction de la position de ce nombre dans la pile. En pseudo-code :

			on calcule la taille de la pile a
			on traite les cas o√π il y a moins de trois √©l√©ments dans la pile
			tant qu'il y a plus de trois √©l√©ments
				on d√©termine l index le plus petit
				s'il est dans la moiti√© haute de la pile 
					on le fait remonter avec des ra jusqu ce qu il soit tout en haut
				s il est dans la moitie basse de la pile
					on le fait remonter avec des rra jusqu ce qu il soit tout en haut
				on le pushe sur b avec pb
			on trie les 3 derniers √©l√©ments de a avec three_sort
			on vide dans a toute la pile b
			c'est tri√© !


### B. algorithme de complexit√© O(n‚àön) :
* **Stat√©gie choisie : range-based sorting strategy**

Nous avons choisi cette variante du chunk-based sort pour son efficacit√© dans la cat√©gorie des algorithmes de complexit√© O(n‚àön). Il s'agit de "pr√©-trier" les nombres en envoyant dans la pile b les nombres qui font partie de la plage [0- ‚àösize] (avec size qui correspond √† la taille de la pile a). Au fur et √† mesure qu'on envoie des nombres dans la pile b, on incr√©mente un compteur i et on adapte l'intervalle qui devient [0- ‚àösize + 1]. Voici la logique de l'impl√©memtation en pseudo-code :

			
			
			on compte le nombre d elements de la stack a = size
			on determine le range (racine de size)*
			on met un incrementateur count a 0
			ETAPE 1 : ON PRE-TRIE 
			tant que a n est pas vide
				si index est compris dans l'intervalle [0 ; range + i]
					on pushe dans b
					si index < i (cad s'il s'agit d'un petit index)
						rb (on l'envoie au fond de la pile b)
						on incr√©mente le compteur
				sinon on fait tourner la pile a (avec ra)	
			NB a la fin de cette boucle, les nombres sont pre tries, grands au dessus, petits en dessous, moyens au milieu
			ETAPE 2 : ON TRIE LA PILE B "PRE-TRIEE"
			tant que b n'est pas vide
			on regarde si l'un des deux plus grands index se trouve sur le dessus de la pile (c'est une optimisation!)
			si oui 
				on pushe dans a
				s il y a plus d¬¥un element dans a
					on v√©rifie que les deux nombres en haut de la pile a sont tri√©s 
					si ce n'est pas le cas, on les swap
			si non
				on regarde √† quelle position se trouve index_max
				s'il est encore dans la moiti√© haute de la pile
					on fait tourner avec rb
				s¬¥il est dans le bas de la pile
					on le fait remonter avec des rrb

### C. algorithme de complexit√© O(n log n) :
* **Stat√©gie choisie : Radix Sort**

Nous avons s√©lectionn√© le Radix Sort (en base 2) pour son efficacit√© sur les tr√®s grands jeux de donn√©es (N ‚â• 5000). Il s'agit d'un algorithme de complexit√© O(n log n). La strat√©gie ne repose pas sur la comparaison des valeurs entre elles, mais sur le traitement de leur repr√©sentation binaire, du bit de poids faible vers le bit de poids fort. Pour simplifier le traitement (et g√©rer les nombres n√©gatifs), nous associons d'abord chaque nombre √† son rang final (de 0 √† size-1). Ensuite, pour chaque position de bit, nous filtrons la pile a : les nombres ayant un bit √† 0 sont envoy√©s dans la pile b, tandis que ceux ayant un bit √† 1 restent dans la pile a (via rotation). Apr√®s chaque passe, on rassemble tout en reversant b sur a, ce qui ordonne progressivement la liste.

Voici la logique de l'impl√©mentation en pseudo-code :


		Initialisation & Pr√©-traitement :
		On parcourt la pile A pour associer √† chaque nombre son **index final** (de 0 √† size-1).
		(Cela permet de ne travailler qu'avec des nombres positifs et simplifie le tri binaire).
		On d√©termine le nombre de bits n√©cessaires (`max_bits`) pour √©crire le plus grand index.
		On initialise un compteur de position de bit `i` √† 0.

		BOUCLE PRINCIPALE : TRAITEMENT BIT PAR BIT
		TANT QUE `i` est inf√©rieur √† `max_bits` :

    		Phase 1 : Distribution (Tri selon le bit i)
    		On r√©p√®te l'op√©ration `size` fois (pour chaque √©l√©ment de A) :
        	On regarde l'index du nombre au sommet de la pile A (head).
        		SI le bit √† la position `i` est √©gal √† 0 :
            		On le pousse dans la pile B (`pb`).
        		SINON (si le bit est √©gal √† 1) :
           			 On le laisse dans A et on fait tourner la pile (`ra`).
    
    		Phase 2 : Rassemblement (Reconstitution)
    		TANT QUE la pile B n'est pas vide :
        		On repousse tout le contenu de B sur A (`pa`).
        		(Comme B est vid√© sur A, les nombres ayant un '0' se retrouvent au-dessus, et l'ordre relatif est conserv√©).

			Phase 3 : Passage au bit suivant
    		On incr√©mente `i` (on passe au bit de poids sup√©rieur).

		√Ä la fin de la boucle (apr√®s le traitement du dernier bit), la pile A est enti√®rement tri√©e.


</details>

<details>
<summary><strong>üìù Algorithme adaptatif</strong></summary>


Pour d√©finir la strat√©gie √† adopter, nous nous sommes appuy√©s sur des tests prenant en compte le d√©sordre et la longueur de la liste √† trier. Les donn√©es report√©es sont repr√©sentatives d'un score "moyen"√† "mauvais" (sauf pour le radix sort o√π le nombre d'op√©rations est fixe quel que soit le d√©sordre). Les meilleurs r√©sultats sont indiqu√©s en **gras**. :

</details>

<details>
<summary><strong>üìä Analyse</strong></summary>

### üìä Analyse des Petites Listes (N = 5, 10, 20)

Ce tableau pr√©sente l'√©volution de la performance sur les petites tailles de listes. Il justifie pourquoi l'algorithme adaptatif moyen ou complexe n'est activ√© qu'au-del√† de 20 √©l√©ments.

* **Sel** : Selection Sort (Tri simple optimis√©).
* **Ran** : Range-Based Sort (Tri par paquets $O(N\sqrt{N})$).
* **Rad** : Radix Sort (Binaire $O(N \log N)$).

| D√©sordre | N=5 (Sel) | N=5 (Ran) | N=5 (Rad) | N=10 (Sel) | N=10 (Ran) | N=10 (Rad) | N=20 (Sel) | N=20 (Ran) | N=20 (Rad) |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **0.1** | **6** | 13 | 25 | **16** | 24 | 50 | **32** | 55 | 212 |
| **0.2** | **7** | 15 | 25 | **20** | 28 | 50 | **38** | 60 | 212 |
| **0.3** | **8** | 15 | 25 | **21** | 27 | 50 | **55** | 65 | 212 |
| **0.4** | **7** | 13 | 25 | **21** | 36 | 50 | **75** | 70 | 212 |
| **0.5** | **8** | 12 | 25 | **24** | 31 | 50 | 92 | **75** | 212 |
| **0.6** | **9** | 17 | 25 | **19** | 25 | 50 | 80 | **80** | 212 |
| **0.7** | **8** | 15 | 25 | **23** | 29 | 50 | **65** | 85 | 212 |
| **0.8** | **9** | 16 | 25 | **24** | 38 | 50 | **50** | 90 | 212 |
| **0.9** | **8** | 17 | 25 | **23** | 42 | 50 | **40** | 95 | 212 |
| **1.0** | **8** | 18 | 25 | **23** | 40 | 50 | **38** | 98 | 212 |



#### üí° Analyse de la progression :

1.  **H√©g√©monie du Selection Sort ($N \le 10$)** :
    * Jusqu'√† 10 √©l√©ments, le **Selection Sort** domine totalement. Il est 2 √† 3 fois plus rapide que le Radix ou le Range Sort.
    * *Conclusion :* Un algorithme simple est imp√©ratif pour ces tailles afin d'√©viter le gaspillage de mouvements. Le **selection Sort** reste le plus efficace pour les listes de moins de 20 nombres. Le **range_based_sort** devient ensemble plus efficace lorsque le d√©sordre est autour de 0.5.
    * Le **Radix** est ici hors-jeu (212 coups) : le co√ªt fixe des passes binaires (5 bits n√©cessaires) est trop lourd pour une si petite liste.

### üìä Analyse des Listes Moyennes (N = 50 √† 500)

* **Sel** : Selection Sort (Tri simple optimis√©).
* **Ran** : Range-Based Sort (Tri par paquets $O(N\sqrt{N})$).
* **Rad** : Radix Sort (Binaire $O(N \log N)$).

| D√©sordre | N=50 (Sel) | N=50 (Ran) | N=50 (Rad) | N=100 (Sel) | N=100 (Ran) | N=100 (Rad) | N=500 (Sel) | N=500 (Ran) | N=500 (Rad) |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **0.1** | **100** | 111 | 467 | **180** | 350 | 1050 | 3900 | **1239** | 6784 |
| **0.2** | **127** | 138 | 467 | **250** | 380 | 1050 | 5688 | **1600** | 6784 |
| **0.3** | **125** | 152 | 467 | **350** | 450 | 1050 | 8546 | **2122** | 6784 |
| **0.4** | 310 | **200** | 467 | 600 | **520** | 1050 | 9183 | **2343** | 6784 |
| **0.5** | 514 | **241** | 467 | 900 | **600** | 1050 | 11123 | **2779** | 6784 |
| **0.6** | 388 | **253** | 467 | 800 | **680** | 1050 | 14037 | **3019** | 6784 |
| **0.7** | **235** | 293 | 467 | **500** | 750 | 1050 | 16226 | **3443** | 6784 |
| **0.8** | **178** | 292 | 467 | **400** | 820 | 1050 | 22416 | **4053** | 6784 |
| **0.9** | **143** | 332 | 467 | **300** | 950 | 1050 | 25798 | **4482** | 6784 |
| **1.0** | **143** | 331 | 467 | **320** | 1100 | 1050 | 25510 | **6355** | 6784 |

#### üí° Analyse comparative :

1.  **N=50 & N=100 (Sel vs Ran) :**
    * Le **Selection Sort (Sel)** reste tr√®s pertinent pour les cas extr√™mes (tr√®s tri√© ou invers√©), car il profite des optimisations apport√©es.
    * Le **Range Sort (Ran)** prend l'avantage uniquement dans la zone de "d√©sordre interm√©diaire" (0.4 √† 0.6).
    * Le **Radix** est trop lourd (co√ªt fixe constant trop √©lev√©).

2.  **N=500 (choix du Range Sort) :**
    * Le **Range Sort (Ran)** devient l'algorithme dominant absolu. Il bat le Radix m√™me dans le pire cas (6355 contre 6794 coups).
    * Le **Selection Sort** s'effondre totalement (d√©passant les 25 000 coups) et n 'est plus pertinent √† partir de ce seuil.

	### üìä Analyse grandes Listes (N = 1000, 3000)

Pour ces tailles, les algorithmes de type $O(N^2)$ (Selection Sort) sont exclus car trop lents.
Ce tableau compare uniquement le **Range-Based Sort** (Tri par paquets) et le **Radix Sort** (Base 2).

* **Ran** : Range-Based Sort (Optimis√© avec heuristiques).
* **Rad** : Radix Sort (Performance stable peu importe le d√©sordre).

| D√©sordre | N=1000 (Ran) | N=1000 (Rad) | N=3000 (Ran) | N=3000 (Rad) |
| :---: | :---: | :---: | :---: | :---: |
| **0.1** | **2 548** | 15 060 | **11 445** | 55 172 |
| **0.2** | **4 596** | 15 060 | **21 757** | 55 172 |
| **0.3** | **5 594** | 15 060 | **30 023** | 55 172 |
| **0.4** | **6 671** | 15 060 | **38 339** | 55 172 |
| **0.5** | **8 239** | 15 060 | **45 636** | 55 172 |
| **0.6** | **9 276** | 15 060 | 55 712 | **55 172** |
| **0.7** | **10 420** | 15 060 | 58 012 | **55 172** |
| **0.8** | **11 641** | 15 060 | 62 518 | **55 172** |
| **0.9** | **11 757** | 15 060 | 63 386 | **55 172** |
| **1.0** | 19 521 | **15 060** | 93 646 | **55 172** |

### üìä Analyse des tr√®s Grandes Listes (N = 5000, 10000)

On observe que pour des volumes tr√®s importants, la stabilit√© du **Radix Sort** finit par surpasser le **Range Sort** d√®s que le d√©sordre est significatif. Pour une liste de 10000 nombres, le **radix** l'emporte √† tous les coups.

| D√©sordre | N=5000 (Ran) | N=5000 (Rad) | N=10000 (Ran) | N=10000 (Rad) |
| :---: | :---: | :---: | :---: | :---: |
| **0.2** | **82 462** | 100 190 | 224 167 | **215 392** |
| **0.5** | 111 601 | **100 190** | 385 956 | **215 392** |
| **0.8** | 110 874 | **100 190** | 502 721 | **215 392** |

</details>

<details>
<summary><strong>üìâ Calcul de la complexit√© des algorithmes</strong></summary>


Cette section a pour but de v√©rifier si nos algorithmes correspondent bien √† leur complexit√© th√©orique annonc√©e, en utilisant la formule du facteur de croissance ($\alpha$).

---

#### üê¢ Algorithme simple (select_sort)

On prend comme rep√®res les valeurs pour **N = 100** et **N = 500** (pire cas).

* Calcul du grossissement de la liste : $Ratio_N = 500/100 = \mathbf{5}$
* Calcul du grossissement du nombre d'op√©rations : $Ratio_{Ops} = 25\,798 / 900 \approx \mathbf{28.6}$

On est donc proche de $O(N^2)$ car $5^2 = 25$. On applique la formule logarithmique pour trouver la puissance exacte :

$$
\alpha = \frac{\ln(28.6)}{\ln(5)} \approx \frac{3.35}{1.61} \approx \mathbf{2.08}
$$

> **Conclusion :** L'exposant $\alpha$ √©tant tr√®s proche de **2**		(NB : r√©sultat th√©orique attendu : ln(25) / ln(5) = 2)), cela confirme que la complexit√© de l'algorithme est **$O(N^2)$**. C'est pour cette raison que cet algorithme n'est plus utilis√© au-del√† de 100 nombres (l'explosion du nombre de coups devient ing√©rable).

---

#### üêá Algorithme moyen (range-based sorting strategy)

On compare l'√©volution du nombre d'op√©rations sur des listes de taille moyenne √† grande avec un d√©sordre standard (0.5).

* **Donn√©es mesur√©es :** $N = 1000$ (8 239 coups) et $N = 3000$ (45 636 coups).
* Calcul du grossissement de la liste : $Ratio_N = 3000 / 1000 = \mathbf{3}$
* Calcul du grossissement des op√©rations :

$$
Ratio_{Ops} = \frac{45 636}{8 239} \approx \mathbf{5.54}
$$

Th√©oriquement, la complexit√© $N\sqrt{N}$ donnerait ici $3\sqrt{3} \approx 5.19$. On est tr√®s proche. On confirme en appliquant la formule logarithmique :

$$
\alpha = \frac{\ln(5.54)}{\ln(3)} \approx \frac{1.71}{1.10} \approx \mathbf{1.56}
$$

> **Conclusion :** L'exposant $\alpha \approx 1.5$ indique une complexit√© proche de **$O(N \sqrt{N})$** (NB : r√©sultat th√©orique : ln(5.19) / ln(3) = 1.49)  C'est nettement plus performant que le Selection Sort ($\alpha \approx 2$), mais cela explique pourquoi le **Range Sort** finit par √™tre d√©pass√© par le **Radix Sort** sur les tr√®s grandes listes.

---

#### üöÄ Algorithme complexe (radix_sort)

Pour le radix_sort, nous observons une grande stabilit√© sur les tr√®s grandes listes. Nous allons d√©montrer pourquoi la complexit√© th√©orique $O(N \times k)$ est strictement √©quivalente √† $O(N \log N)$.

* **Donn√©es mesur√©es :** $N = 5000$ (100 190 coups) et $N = 10000$ (215 392 coups).
* **Ratio observ√© :**
    $$
    Ratio_{Ops} = \frac{215 392}{100 190} \approx \mathbf{2.15}
    $$

**1. Calcul via les bits ($N \times k$) :**
* Pour $N = 5000$ : Il faut **13 bits** ($2^{13} = 8192$).
* Pour $N = 10000$ : Il faut **14 bits** ($2^{14} = 16384$).

$$
Ratio_{Th√©orique} = \frac{10000 \times 14}{5000 \times 13} = 2 \times \frac{14}{13} \approx \mathbf{2.15}
$$

**2. Calcul via les logarithmes ($N \log N$) :**
En base 2, le nombre de bits $k$ est d√©fini par le logarithme : $k \approx \log_2(N)$.

$$
Ratio_{Log} = \frac{10000 \times \log_2(10000)}{5000 \times \log_2(5000)} \approx 2 \times \frac{13.29}{12.29} \approx \mathbf{2.16}
$$

> **Conclusion :** Les deux calculs m√®nent au m√™me r√©sultat (~2.15), ce qui confirme que l'algorithme suit bien une complexit√© **$O(N \log N)$**.

---

### üìä R√©capitulatif 

| Algorithme | Ratio N test√© | Ratio Ops Mesur√© | Exposant calcul√© ($\alpha$) | Complexit√© Valid√©e |
| :--- | :---: | :---: | :---: | :--- |
| **Selection** | x5 | x28.6 | **2.08** | $O(N^2)$ |
| **Range** | x3 | x5.54 | **1.56** | $O(N\sqrt{N})$ |
| **Radix** | x2 | x2.15 | **1.10** | $O(N \log N)$ |
</details>

</details>

## 6. Contributions

<details>
<summary><strong>üë• Contributions</strong></summary>

<br>

| Fonctionnalit√© | Auteurs / Responsables |
| :--- | :--- |
| **Parsing & Validation** | `stmaire` |
| **Gestion des Flags** | `marberge` |
| **Benchmark & Tests** | `marberge` |
| **Op√©rations (Instructions)** | `marberge` & `stmaire` |
| **Algo : Simple Sort** | `marberge` & `stmaire` |
| **Algo : Medium Sort** | `stmaire` |
| **Algo : Complex Sort** | `marberge` |
| **S√©lecteur Adaptatif** | `stmaire` |
| **Documentation (README)** | `stmaire` |

</details>
